\documentclass[12pt,a4paper]{article}

% XeLaTeX specific packages
\usepackage{fontspec} % Allows using system fonts
\usepackage{xeCJK}    % For CJK (Chinese, Japanese, Korean) support
\usepackage{unicode-math} % For modern math typesetting with OpenType math fonts

% Set main, CJK, and math fonts
% \setmainfont{Arial} % Original choice
\setmainfont{Times New Roman} % Example: Switched to Times New Roman
\setCJKmainfont{Noto Serif CJK TC}     % Fallback to previously working font if Noto Sans CJK TC is not found
\setCJKmonofont{Sarasa Term SC Nerd} % Or your preferred CJK monospace font
\setmathfont{XITS Math}       % Example math font (pairs well with Times)

% Common LaTeX packages
\usepackage{graphicx} % For including images
\usepackage{amsmath}  % For advanced math typesetting (load before unicode-math or let unicode-math handle it)
\usepackage{amsfonts} % For math fonts (often covered by amssymb or unicode-math)
\usepackage{amssymb}  % For math symbols (often covered by unicode-math)
\usepackage{booktabs} % For professional quality tables
\usepackage{array}    % For extending array and tabular environments
% \usepackage{parskip}  % For paragraphs separated by vertical space instead of indentation (keep if you prefer this style)
\usepackage{geometry} % For page layout customization
\geometry{a4paper, margin=1in}
\usepackage{makecell} % For multi-line cells in tables, and general table enhancements
\usepackage{tabularx} % For tables with adjustable-width columns
\usepackage{siunitx}  % For typesetting numbers and units, good for aligning numbers
% Add recommended siunitx v3 setup to replace deprecated detect-all behavior
\sisetup{
  mode = match, % Attempt to match font settings from surrounding text
  propagate-math-font = true,
  reset-math-version = false,
  reset-text-family = false,
  reset-text-series = false,
  reset-text-shape = false,
  text-family-to-math = true,
  text-series-to-math = true
}
\usepackage{rotating} % For rotating elements, e.g., wide tables to landscape

\usepackage{microtype} % Improves typography

% Bibliography (using biblatex)
\usepackage[backend=biber, 
            style=numeric, 
            sorting=nyt, 
            sortcites=true, 
            giveninits=true, 
            maxbibnames=99]{biblatex} % Removed compress=true
\addbibresource{refs.bib} % Replace refs.bib with your .bib file name

\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue, pdfborder={0 0 0}]{hyperref} % For hyperlinks - load biblatex before hyperref typically

% Potentially add if you need code listings
% \usepackage{minted}

% For traditional paragraph indentation if parskip is removed
\usepackage{indentfirst} % Indents the first paragraph after a section heading
\setlength{\parindent}{1.5em} % Example: Set paragraph indentation (if not using parskip)

% Title, Author, Date
\title{人体关键点检测研究 \\ % Primary Title
       {\large A Study on Human Keypoint Detection}} % Subtitle (Optional)
\author{你的名字 (Your Name) \\
        你的单位 (Your Affiliation) \\
        \texttt{your.email@example.com}}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
\noindent % Ensure no indent for the abstract
本文摘要... (Your abstract in Chinese here)
\vspace{0.5em} % A little space

\noindent % Ensure no indent for the English abstract
\textbf{Abstract:} Your abstract in English here...
\end{abstract}

\section{引言 (Introduction)}
人体姿态估计（Human Pose Estimation, HPE）是计算机视觉领域的一项基础且关键的任务，旨在从图像或视频中定位人体的关键关节点（如头、肩、肘、腕、髋、膝、踝等）\cite{Sun2019HRNet}。这项技术对于理解人类行为、动作识别、人机交互、运动分析、虚拟现实、医疗康复等众多应用至关重要 \cite{Zhou2016HumanPoseSurvey}。近年来，随着深度学习技术的飞速发展，基于深度学习的HPE方法取得了显著进展，在准确性和鲁棒性方面远超传统方法 \cite{Zhou2016HumanPoseSurvey}。本报告旨在全面回顾过去二十年间基于深度学习的人体关键点检测系统的发展历程，重点梳理主要的技术突破，比较不同方法的性能，分析当前（截至2024年底）在主流基准数据集上的最先进（State-of-the-Art, SOTA）模型，探讨现有挑战，并展望未来的研究方向。我们将涵盖2D和3D姿态估计，单人与多人场景，并深入探讨关键技术创新，包括网络架构的演进、输出表示（热力图 vs. 回归）、损失函数设计以及数据增强策略等。

\section[人体姿态估计：历史演进与关键突破]{人体姿态估计：历史演进与关键突破 \\ (Human Pose Estimation: Historical Evolution and Key Breakthroughs)}
过去二十年见证了人体姿态估计从依赖手工特征和图模型的传统方法，向量深度学习驱动的范式转变。深度学习强大的特征提取和端到端学习能力极大地推动了该领域的发展 \cite{Zhou2016HumanPoseSurvey}。

\subsection{早期深度学习探索 (约2014年): DeepPose}
Toshev和Szegedy于2014年提出的DeepPose \cite{Toshev2014DeepPose} 是将深度神经网络（DNN）应用于端到端人体姿态估计的开创性工作。它将姿态估计建模为一个基于DNN的坐标回归问题，直接从图像回归关节点坐标 \cite{Toshev2014DeepPose}。
DeepPose采用级联DNN回归器结构，后续阶段利用前一阶段预测的关节点位置裁剪更高分辨率的子图像进行精调，从而提高定位精度 \cite{Toshev2014DeepPose}。其初始模型基于AlexNet \cite{Krizhevsky2012ImageNetNIPS}，包含约4000万参数 \cite{Krizhevsky2012ImageNetNIPS}。
尽管DeepPose在当时取得了领先性能（例如，在FLIC数据集上优于先前方法 \cite{Krizhevsky2012ImageNetNIPS}），但直接坐标回归面临非线性映射优化困难、空间泛化能力弱等挑战 \cite{Cao2019OpenPose}。

\subsection{热力图表示法的兴起与CNN架构发展 (约2016-2018年)}
为了解决直接回归的局限性，研究转向基于热力图（Heatmap）的检测方法 \cite{Zhou2016HumanPoseSurvey}。热力图为每个关节点生成一个概率图，峰值对应关节点位置，这种表示对遮挡和模糊更鲁棒，且易于CNN学习 \cite{Cao2019OpenPose}。
Convolutional Pose Machines (CPM) \cite{Cao2019OpenPose}: Wei等人提出的CPM采用多阶段顺序卷积架构，利用中间监督学习空间信息和上下文线索，有效提升了精度 \cite{Cao2019OpenPose}。
Stacked Hourglass Networks \cite{Newell2016StackedHourglass}: Newell等人提出的堆叠沙漏网络成为一个里程碑式的架构 \cite{Newell2016StackedHourglass}。其核心思想是通过对称的、重复的下采样（池化）和上采样模块（形似沙漏）来捕捉和整合多尺度特征 \cite{Newell2016StackedHourglass}。下采样用于捕获全局上下文信息，上采样则用于恢复高分辨率的细节信息 \cite{Liu2020SMSNet}。通过堆叠多个沙漏模块并引入中间监督，网络能够进行反复的自底向上、自顶向下的推理，逐步优化预测 \cite{Newell2016StackedHourglass}。8层堆叠的Hourglass模型在MPII上取得了90.9 PCKh@0.5的成绩，模型参数量约25.1M，计算量约19.1 GFLOPs \cite{Sun2019HRNet}。
Cascaded Pyramid Network (CPN) \cite{Chen2018CPN}: Chen等人提出的CPN采用级联金字塔结构，包含GlobalNet和RefineNet \cite{Chen2018CPN}。GlobalNet基于特征金字塔网络（FPN）学习多尺度特征表示，有效定位"简单"关键点；RefineNet则结合GlobalNet的多层级特征和在线难例关键点挖掘损失（online hard keypoint mining loss），专门处理遮挡或不可见的"困难"关键点 \cite{Chen2018CPN}。CPN在COCO test-dev上达到了73.0 AP \cite{Chen2018CPN}，显著优于之前的SOTA。其基于ResNet-50的版本计算量约为6.2 GFLOPs \cite{Chen2018CPN}。
SimpleBaseline \cite{Sun2019HRNet}: Xiao等人提出了一种极其简洁但效果惊人的基线模型 \cite{Xiao2018SimpleBaselines}。它在ResNet等骨干网络后添加几个反卷积层来直接预测热力图 \cite{Xiao2018SimpleBaselines}。该方法证明了强大的骨干网络结合简单的解码器即可达到SOTA性能，SimpleBaseline (ResNet-152, 384x288输入) 在COCO test-dev上达到了73.7 AP \cite{Sun2019HRNet}。SimpleBaseline (ResNet-50, 256x192输入) 在COCO val上达到70.4 AP，参数量34.0M，计算量8.9 GFLOPs \cite{Sun2019HRNet}。

\subsection{高分辨率表示学习 (约2019年): HRNet}
Sun等人提出的High-Resolution Network (HRNet) \cite{Sun2019HRNet} 旨在解决以往方法中（如Hourglass）下采样导致高分辨率信息损失的问题 \cite{Sun2019HRNet}。
HRNet的核心思想是在整个网络处理过程中始终保持高分辨率特征表示 \cite{Sun2019HRNet}。它从一个高分辨率子网开始，逐步并行添加从高到低分辨率的子网，并在不同分辨率的并行子网间进行重复的多尺度特征融合（repeated multi-scale fusions）\cite{Sun2019HRNet}。这种设计使得高分辨率表示能够持续接收来自其他分辨率表示的信息，从而获得语义丰富且空间精确的特征图，尤其适合于姿态估计这类对位置敏感的任务 \cite{Sun2019HRNet}。
HRNet在COCO和MPII等基准上取得了当时的SOTA性能 \cite{Sun2019HRNet}。例如，HRNet-W48 (384x288输入) 在COCO test-dev上达到75.5 AP，参数量63.6M，计算量32.9 GFLOPs；HRNet-W32 (256x256输入) 在MPII test上达到92.3 PCKh@0.5，参数量28.5M，计算量9.5 GFLOPs \cite{Sun2019HRNet}。后续还出现了HigherHRNet \cite{Sun2019HRNet}、Lite-HRNet \cite{Sun2019HRNet} 等改进版本。

\subsection{Transformer时代 (约2021年至今): ViTPose, PCT, Hulk等}
受Transformer在自然语言处理和图像识别领域成功的启发，研究者开始将其应用于HPE \cite{Wang2023TransformerSurvey}。Transformer的自注意力机制（Self-Attention）能够有效捕捉图像或序列中的长距离依赖关系，这对于理解全局姿态结构和处理遮挡尤为重要 \cite{Wang2023TransformerSurvey}。
ViTPose \cite{Xu2022ViTPose}: Xu等人提出的ViTPose采用简洁的Vision Transformer (ViT) 作为骨干网络，配合轻量级解码器进行姿态估计 \cite{Xu2022ViTPose}。它展示了纯Transformer架构在HPE任务上的强大潜力，具有良好的模型结构简单性、尺寸可扩展性（从100M到1B参数）、训练范式灵活性和知识可迁移性 \cite{Xu2022ViTPose}。ViTPose及其增强版ViTPose+在COCO等基准上取得了SOTA或接近SOTA的性能 \cite{Xu2022ViTPose}。例如，ViTPose (ViTAE-G, ensemble) 在COCO test-dev上是SOTA之一 \cite{Xu2022ViTPose}。ViTPose-Base在COCO val上达到76.9 AP \cite{Sun2023SHaRPose}。
PCT (Pose as Compositional Tokens) \cite{Geng2023PCT}: Geng等人提出将人体姿态表示为M个离散的组合式Token，每个Token表征一个包含若干相互依赖关节点的子结构 \cite{Geng2023PCT}。姿态估计被转化为一个分类任务，预测图像对应的M个Token类别，然后通过预训练的解码器恢复姿态 \cite{Geng2023PCT}。这种结构化表示旨在更好地建模关节点间的依赖关系，尤其在遮挡场景下表现出色 \cite{Geng2023PCT}。PCT (Swin-L) 在MPII test上取得了94.3 PCKh@0.5的SOTA成绩 \cite{Geng2023PCT}。
Hulk (Human-centric universal knowledge translator) \cite{Wang2023Hulk}: Wang等人提出了一个多模态、多任务的通用人体中心感知模型Hulk \cite{Wang2023Hulk}。它将不同任务（2D/3D视觉、骨骼、视觉语言）的输入输出统一为连续（坐标）和离散（语言）两种基本表示，并采用编码器-解码器架构进行模态转换 \cite{Wang2023Hulk}。Hulk在包括AIC姿态估计在内的多个基准上取得了SOTA性能 \cite{Wang2023Hulk}。Hulk (ViT-L, Finetune) 在AIC test上达到37.1 AP \cite{Wang2023HulkCVPR}。

这一演进历程清晰地展示了HPE领域不断追求更优特征表示（从局部到全局，从低分辨率到高分辨率，从CNN到Transformer）和更有效学习范式（从直接回归到热力图检测，从纯监督到利用自监督/无监督信号）的技术趋势。每一次架构的革新都旨在克服前代方法的局限性，以应对姿态估计中固有的挑战，如遮挡、外观变化和复杂的关节联动。

\section{核心方法论比较 (Comparison of Core Methodologies)}
在深度学习HPE中，存在两种主要的实现范式：处理多人场景的\textbf{自顶向下（Top-Down）与自底向上（Bottom-Up）方法，以及表示关节点位置的热力图（Heatmap）与坐标回归（Regression）}方法。理解这些方法的差异对于选择和评估HPE系统至关重要。

\subsection{自顶向下 vs. 自底向上 (Top-Down vs. Bottom-Up)}
这两种方法主要用于解决多人姿态估计问题，即在包含多个个体的图像或视频中估计每个人的姿态 \cite{Zhou2016HumanPoseSurvey}。

\begin{table}[htbp]
\centering
\caption{自顶向下与自底向上多人姿态估计方法比较 \label{tab:topdown_vs_bottomup}}
\begin{tabularx}{\textwidth}{|l|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|} % Changed tabular to tabularx, width to \textwidth, and p{} to X
\toprule
\textbf{特征} & \textbf{自顶向下 (Top-Down)} & \textbf{自底向上 (Bottom-Up)} \\
\midrule
核心流程 & \makecell[tl]{1. 人体检测： 首先使用目标检测器（如Faster R-CNN, \\ YOLO）检测图像中所有的人体边界框 \cite{Zhou2016HumanPoseSurvey}。\\ 2. 单人姿态估计： 对每个检测框内的区域，应用单人\\姿态估计算法预测关节点 \cite{Zhou2016HumanPoseSurvey}。} & \makecell[tl]{1. 关节点检测： 首先检测图像中所有可能的身体关键\\点，不区分个体 \cite{Lin2014COCO}。\\ 2. 关节点分组： 然后通过学习部件间的亲和度（如Part \\ Affinity Fields, PAFs \cite{Simon2017HandKeypoint}）或关联嵌入（Associative \\ Embedding \cite{Cao2019OpenPose}）等方法，将检测到的关节点组合\\成属于不同个体的骨架 \cite{Zhou2016HumanPoseSurvey}。} \\
\midrule
代表模型 & \makecell[tl]{CPN \cite{Chen2018CPN}, SimpleBaseline \cite{Xiao2018SimpleBaselines}, HRNet \cite{Sun2019HRNet}, ViTPose \cite{Xu2022ViTPose} (通常采用此流程)} & \makecell[tl]{OpenPose \cite{Cao2019OpenPose}, Associative Embedding \cite{Cao2019OpenPose}, HigherHRNet \cite{Sun2019HRNet}, DEKR \cite{Cao2019OpenPose}} \\
\midrule
优势 & \makecell[tl]{- 通常精度更高，因为可以利用人体检测框提供的尺度和位置先验信息，专注于单人姿态估计 \cite{Papandreou2017TowardsAccurate}。\\ - 对遮挡和复杂背景相对更鲁棒，因为可以利用框内上下文推断被遮挡的关节点 \cite{Li2019CrowdPose}。} & \makecell[tl]{- 推理时间通常与人数无关，对于非常拥挤的场景（大量人群）可能更高效 \cite{Li2019CrowdPose}。\\ - 不需要额外的人体检测器，是端到端的。} \\
\midrule
劣势 & \makecell[tl]{- 性能严重依赖人体检测器的精度，检测失败或不准确会直接影响姿态估计结果 \cite{Zhang2024HPEReview}。\\ - 计算成本随人数增加而线性增长，处理非常拥挤的场景时速度可能较慢 \cite{Li2019CrowdPose}。} & \makecell[tl]{- 在关节点分组阶段容易出错，尤其是在人群密集、人体相互遮挡严重的情况下 \cite{Andriluka2014MPII}。\\ - 对小尺度人物的检测可能不如Top-Down方法。} \\
\midrule
适用场景 & 对精度要求高、人数适中或稀疏的场景。 & 对实时性要求高、人群非常密集的场景。 \\
\bottomrule
\end{tabularx} % Changed tabular to tabularx
\end{table}

研究表明，在处理遮挡和拥挤场景时，Top-Down方法（如ViTPose）通常表现出更好的鲁棒性 \cite{Li2019CrowdPose}。这主要归因于其能够利用检测框内的上下文信息来推断被遮挡的关节点，并且对每个个体进行独立处理，减少了来自其他个体的干扰 \cite{Li2019CrowdPose}。然而，其推理时间与人数成正比，而Bottom-Up方法（如DEKR）的推理时间相对稳定，使其在极度拥挤的场景下具有速度优势 \cite{Li2019CrowdPose}。因此，方法的选择需要根据具体的应用场景和性能需求进行权衡。

\subsection{热力图 vs. 坐标回归 (Heatmap vs. Coordinate Regression)}
这两种方法代表了预测关节点位置的两种主要技术路线 \cite{Toshev2014DeepPose}。

\begin{table}[htbp]
\centering
\caption{热力图回归与直接坐标回归方法比较 \label{tab:heatmap_vs_regression}}
\begin{tabularx}{\textwidth}{|l|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|} % Changed tabular to tabularx
\toprule
\textbf{特征} & \textbf{热力图回归 (Heatmap Regression)} & \textbf{直接坐标回归 (Direct Coordinate Regression)} \\
\midrule
核心思想 & 为每个关节点预测一个概率热力图，图上每个像素值表示该点是对应关节点的概率。通常使用二维高斯分布作为真值 \cite{Wang2023TransformerSurvey}。最终坐标通过取热力图的峰值（argmax）或期望（integral regression）得到 \cite{Huang2021BiasCompensated}。 & 直接将图像特征映射到关节点的 (x,y)(2D) 或(x,y,z) (3D) 坐标 \cite{Toshev2014DeepPose}。 \\
\midrule
代表模型 & \makecell[tl]{CPM \cite{Cao2019OpenPose}, Hourglass \cite{Newell2016StackedHourglass}, CPN \cite{Chen2018CPN}, SimpleBaseline \cite{Xiao2018SimpleBaselines}, HRNet \cite{Sun2019HRNet}, ViTPose \cite{Xu2022ViTPose} (大部分SOTA模型采用此方法)} & \makecell[tl]{DeepPose \cite{Toshev2014DeepPose}, Integral Human Pose Regression (采用Soft-Argmax) \cite{Cao2019OpenPose}} \\
\midrule
优势 & \makecell[tl]{- 精度更高： 通过密集的像素级监督，更好地利用了空间上下文信息，对遮挡、模糊更鲁棒 \cite{Toshev2014DeepPose}。\\ - 隐式建模不确定性： 热力图的分布可以一定程度表示定位的不确定性 \cite{Toshev2014DeepPose}。\\ - 易于CNN学习： 生成热力图是CNN擅长的密集预测任务。} & \makecell[tl]{- 概念简单，端到端： 直接输出坐标，无需后处理（如从热力图解码坐标）。\\ - 计算效率可能更高： 输出维度低（2K或3K坐标 vs. HxWxK热力图）。} \\
\midrule
劣势 & \makecell[tl]{- 量化误差： 将连续坐标离散化到热力图网格引入量化误差，尤其在低分辨率热力图或输入图像下影响显著 \cite{Toshev2014DeepPose}。\\ - 计算/内存开销大： 生成和存储高分辨率热力图需要较大计算和内存资源。\\ - 后处理： 需要从热力图中解码出精确坐标（argmax或soft-argmax），argmax不可微，soft-argmax（积分回归）虽可微但存在固有偏差 \cite{Huang2021BiasCompensated}。\\ - 多峰值模糊性： 在对称或遮挡情况下，热力图可能出现多个峰值，导致定位模糊 \cite{Zhang2024HPEReview}。} & \makecell[tl]{- 精度通常较低： 直接从高维图像特征回归到低维坐标难度大，非线性映射难以优化 \cite{Cao2019OpenPose}。\\ - 缺乏空间信息： 不易利用局部图像证据和空间约束。\\ - 对数据偏差敏感。} \\
\midrule
关键问题 & 量化误差、计算开销、解码偏差、多峰值模糊 & 优化难度、空间信息利用不足 \\
\bottomrule
\end{tabularx} % Changed tabular to tabularx
\end{table}

历史上，热力图方法因其优越的性能和泛化能力而逐渐主导了HPE领域 \cite{Toshev2014DeepPose}。它通过提供密集的像素级监督信号，使网络能够更好地学习空间上下文信息，从而在处理遮挡和外观变化方面表现更佳 \cite{Toshev2014DeepPose}。然而，热力图方法并非没有缺点。将连续的真实坐标映射到离散的热力图网格会引入量化误差，这个问题在输入图像分辨率较低时尤为突出，此时热力图方法的优势相比坐标回归会减弱 \cite{Toshev2014DeepPose}。此外，从热力图中解码精确坐标也存在挑战：简单的argmax操作不可微，而可微的积分回归（soft-argmax）虽然实现了端到端训练，但被发现存在固有偏差（induced bias），可能导致网络学习到过于尖锐的热力图以补偿偏差，反而影响精度 \cite{Huang2021BiasCompensated}。研究人员正通过引入隐式神经表示（如NerPE \cite{Zhan2022ContinuousHeatmap}）来生成任意分辨率的连续热力图，或设计偏差补偿机制（如BCIR \cite{Huang2021BiasCompensated}）以及改进损失函数（如Adaptive Wing Loss \cite{Wang2019AdaptiveWing}）来解决这些问题。

\section{State-of-the-Art (SOTA) 性能分析 (SOTA Performance Analysis)}
评估HPE模型的性能通常在标准基准数据集上进行，主要包括COCO \cite{Lin2014COCO}, MPII \cite{Andriluka2014MPII}, AIC \cite{He2022MAE}（主要用于2D）和Human3.6M \cite{Ionescu2014Human36M}（主要用于3D）。评估指标也因数据集和任务（2D/3D）而异。

\subsection{常用评估指标 (Common Evaluation Metrics)}
Object Keypoint Similarity (OKS) based AP (Average Precision): COCO数据集的主要评价指标 \cite{Lin2014COCO}。OKS衡量预测关键点与真值关键点之间的相似度，类似于目标检测中的IoU。计算公式考虑了预测点与真值点的距离、目标尺度以及关键点类型的可见性与重要性（通过常数ki控制衰减）\cite{Lin2014COCO}。AP是在不同OKS阈值（通常从0.5到0.95，步长0.05）下的平均精度，综合评估模型在不同定位精度要求下的性能。常用的还有AP50 (OKS=0.5), AP75 (OKS=0.75), APM (中等目标), APL (大目标) \cite{Lin2014COCO}。

Percentage of Correct Keypoints (PCK): MPII数据集的主要评价指标 \cite{Lin2014COCO}。如果预测关键点与真值关键点之间的距离在某个阈值内，则认为该关键点预测正确 \cite{Lin2014COCO}。阈值通常是相对于人体尺寸进行归一化的，例如PCKh@0.5表示阈值为头部骨骼长度的50\% \cite{Lin2014COCO}。PCK简单直观，但对肢体长度敏感（PCP指标的缺点），PCKh通过头部尺寸归一化缓解了这个问题 \cite{Andriluka2014MPII}。

Mean Per Joint Position Error (MPJPE): 3D姿态估计常用指标，计算预测的3D关节点坐标与真值坐标之间的平均欧氏距离（通常以毫米mm为单位）\cite{Li2024Review3DHPE}。 % UserConfirmContext60 for MPJPE source or use Li2024Review3DHPE or Ionescu2014Human36M if appropriate

Procrustes Aligned MPJPE (PMPJPE / PA-MPJPE): 在计算MPJPE之前，通过刚性变换（旋转、平移、缩放）将预测姿态与真值姿态对齐，以消除全局对齐误差，更关注姿态本身的结构准确性 \cite{Li2024Review3DHPE}。 % UserConfirmContext60 for PMPJPE source or use Li2024Review3DHPE or Ionescu2014Human36M if appropriate

\subsection{当前SOTA模型及性能 (Current SOTA Models and Performance)}
截至2024年底，基于公开信息（如Papers With Code及相关论文），各主要基准上的SOTA模型和性能大致如下（注意：SOTA状态是动态变化的）：

\begin{sidewaystable} % Replaces table environment
\centering
\scriptsize
\caption{部分SOTA模型在主流基准上的性能与复杂度比较 (数据来自相关文献，"-"表示数据缺失) \label{tab:sota_performance_rotated}} % Consider a new label if you keep both versions
\begin{tabularx}{\textheight}{|l|>{\raggedright\arraybackslash}X|l|S[table-format=2.1]|S[table-format=2.1, parse-numbers=false]|S[table-format=2.1]|l|} % Updated S column definitions
\toprule
\textbf{数据集 (任务)} & \textbf{SOTA 模型 (Backbone, 配置)} & \textbf{指标} & {\textbf{性能值}} & {\textbf{参数量}} & {\textbf{计算量}} & \textbf{来源} \\ % Used {} to protect headers for S columns
\midrule
COCO test-dev (2D) & ViTPose (ViTAE-G, ensemble) & AP & 81.1 & {--} & {--} & \cite{Xu2022ViTPose} \\
& Hulk (ViT-L) & AP & 78.3 & {--} & {--} & \cite{Wang2023HulkCVPR} \\
& SHaRPose-Base & AP & 76.7 & \multicolumn{2}{c|}{{-(比ViTPose-Base少25\%)}} & \cite{Sun2023SHaRPose} \\ % Added {} around the text in multicolumn for safety
& SimpleBaseline (ResNet-152, 384x288) & AP & 73.7 & {68.6M} & 35.6 & \cite{Sun2019HRNet} \\
& CPN (ensemble) & AP & 73.0 & {--} & {--} & \cite{Chen2018CPN} \\
& HRNet-W48 (384x288, +extra data) & AP & 77.0 & {63.6M} & 32.9 & \cite{Sun2019HRNet} \\
\midrule
MPII test (2D) & PCT (Swin-L) & PCKh@0.5 & 94.3 & {--} & {--} & \cite{Geng2023PCT} \\
& PCT (Swin-B) & PCKh@0.5 & 93.8 & {--} & {--} & \cite{Geng2023PCT} \\ 
& TransPose & PCKh@0.5 & 93.5 & {--} & {--} & \cite{Yang2020TransPose} \\ 
& UniHCP (FT) & PCKh@0.5 & 93.2 & {--} & {--} & \cite{Wang2022UniHCP} \\ 
& HRNet-W32 (256x256) & PCKh@0.5 & 92.3 & {28.5M} & 9.5 & \cite{Sun2019HRNet} \\
& Stacked Hourglass (8 stages) & PCKh@0.5 & 90.9 & {25.1M} & 19.1 & \cite{Sun2019HRNet} \\
\midrule
AIC test (2D) & Hulk (ViT-L, Finetune) & AP & 37.1 & {--} & {--} & \cite{Wang2023HulkCVPR} \\
& Hulk (ViT-B, Finetune) & AP & 35.6 & {--} & {--} & \cite{Wang2023HulkCVPR} \\
& HRFormer (HRFormer-B) & AP & 34.4 & {--} & {--} & \cite{Wang2023HulkCVPR} \\
& UniHCP (finetune) & AP & 33.6 & {--} & {--} & \cite{Wang2023HulkCVPR} \\
& HRNet (HRNet-w48) & AP & 33.5 & {63.6M} & {--} & \cite{Wang2023HulkCVPR} \\ 
\midrule
Human3.6M (3D) & FTCM & MPJPE & 28.1 & {--} & {--} & \cite{Liu2023FTCMNet} \\ 
& MTF-Transformer & MPJPE & 26.2 & {--} & {--} & \cite{Zhang2023MTFTransformer} \\ 
& Diffpose (CVPR'23) & PMPJPE & {\makecell{28.7 \\ (MPJPE 36.9)}} & {--} & {--} & \cite{Tian2023DiffPoseCVPR}\\ % Wrapped \makecell in {}
& GFPose & PMPJPE & {\makecell{30.5 \\ (MPJPE 35.6)}} & {--} & {--} & \cite{Zhang2022GFPose}\\ % Wrapped \makecell in {}
& DiffPose (ICCV'23) & PMPJPE & {\makecell{30.8 \\ (MPJPE 42.9)}} & {--} & {--} & \cite{Shan2023DiffPoseICCV}\\ % Wrapped \makecell in {}
& STCFormer & PMPJPE & {\makecell{31.8 \\ (MPJPE 40.5)}} & {--} & {--} & \cite{Li2022STCFormer}\\ % Wrapped \makecell in {}
& PoseFormerV2 & PMPJPE & {\makecell{35.6 \\ (MPJPE 45.2)}} & {--} & {--} & \cite{Zhao2023PoseFormerV2}\\ % Wrapped \makecell in {}
& Hulk (ViT-L) & PA-MPJPE & 28.8 & {--} & {--} & \cite{Wang2023HulkCVPR} \\
& Hulk (ViT-L) & MPJPE & 40.3 & {--} & {--} & \cite{Wang2023HulkCVPR} \\
\bottomrule
\end{tabularx}
\end{sidewaystable}

性能与复杂度的权衡:分析上表及相关研究 \cite{Sun2019HRNet} 可以发现，模型性能（如AP, PCKh, MPJPE）与其计算复杂度（参数量Params, 浮点运算次数GFLOPs）之间存在普遍的正相关性，但并非绝对。
架构扩展性: 像HRNet \cite{Sun2019HRNet} 和SimpleBaseline \cite{Sun2019HRNet} 这样的架构，通过增加网络宽度（如HRNet-W32 vs W48）或深度（如ResNet-50 vs ResNet-152），通常能带来精度提升，但伴随着Params和GFLOPs的显著增加。提高输入分辨率也是提升精度的常用手段，但这同样会大幅增加计算量 \cite{Sun2019HRNet}。
Transformer的权衡: Transformer模型如ViTPose \cite{Xu2022ViTPose}, PCT \cite{Geng2023PCT}, Hulk \cite{Wang2023HulkCVPR} 也提供了不同规模的版本（如Base, Large, Huge），允许用户在精度和效率间做选择。例如，Hulk ViT-L在多个任务上优于ViT-B，但计算成本更高 \cite{Wang2023HulkCVPR}。
轻量化趋势: 针对实时应用和资源受限设备，轻量化模型的研究日益增多 \cite{Liu2020SMSNet}。这些模型（如LAP \cite{Zhang2020LAPNet}, EfficientHRNet \cite{Wang2020EfficientHRNet}, SHaRPose \cite{Sun2023SHaRPose}）通过采用深度可分离卷积、通道加权、动态卷积、稀疏表示等技术，旨在显著降低Params和GFLOPs，同时尽可能保持或接近SOTA模型的精度。例如，SHaRPose声称比ViTPose-Base快1.4倍，GFLOPs减少25\%，而AP相当甚至略有提升 \cite{Sun2023SHaRPose}。这表明通过巧妙的结构设计，可以在一定程度上打破精度与效率的强耦合关系。
基准测试的复杂性与SOTA的流动性:需要强调的是，"SOTA"并非一个绝对或统一的概念 \cite{Sun2019HRNet}。
基准依赖性: 一个模型在一个基准（如MPII）上达到SOTA，不代表它在另一个基准（如COCO）上也是最优的。例如，PCT在MPII上领先 \cite{Geng2023PCT}，而ViTPose和Hulk分别在COCO \cite{Xu2022ViTPose} 和AIC \cite{Wang2023HulkCVPR} 上表现突出。这反映了不同数据集侧重的挑战不同（如MPII的姿态多样性 vs. COCO的场景复杂度和遮挡）。
评估设置敏感性: 模型的性能排名对评估设置非常敏感，包括输入分辨率 \cite{Sun2019HRNet}、骨干网络选择 \cite{Sun2019HRNet}、是否使用模型集成 \cite{Sun2019HRNet}、预训练策略 \cite{Sun2019HRNet}、微调 \cite{Sun2019HRNet} 以及Top-Down方法中所用的人体检测器性能 \cite{Chen2018CPN} 等。报告的SOTA通常是在特定优化配置下的峰值性能。
快速发展: HPE领域技术迭代迅速，新的模型和方法不断涌现，SOTA列表也在持续更新中 \cite{Wang2023TransformerSurvey}。
因此，在解读和比较模型性能时，必须仔细考虑所使用的基准、评估指标和具体的实验设置。理解这些细微差别对于准确把握当前技术水平和未来发展方向至关重要。

\section{关键技术创新 (Key Technological Innovations)}
深度学习HPE的进步离不开一系列关键技术的创新，这些创新主要围绕改善特征表示、优化学习目标、提升模型鲁棒性和效率等方面展开。

\subsection{先进的损失函数 (超越MSE) (Advanced Loss Functions (Beyond MSE))}
标准的均方误差（Mean Squared Error, MSE）损失虽然在热力图回归中常用，但存在一些局限性，例如对所有像素同等对待导致背景像素主导损失、对定位精度不敏感、无法很好处理标签噪声或不确定性等 \cite{Huang2021BiasCompensated}。为了克服这些问题，研究者们提出了多种更先进的损失函数：
Wing Loss及其变种 (Adaptive Wing Loss): Wing Loss最初为面部关键点坐标回归设计，旨在放大中小范围误差的影响，提高定位精度 \cite{Feng2018WingLoss}。Adaptive Wing Loss将其思想适配到热力图回归任务，通过自适应调整损失曲线的形状（对前景像素敏感，对背景像素容忍），有效处理了热力图前景背景像素不平衡问题，提升了定位精度，尤其是在面部、手部等密集关键点区域 \cite{Wang2019AdaptiveWing}。
关键点自适应损失 (KAL / FoWKAL): 针对全身姿态估计中不同身体部位（如密集的手/脸关键点 vs. 稀疏的身体关键点）标注密度和尺度差异的问题，Keypoint-wise Adaptive Loss (KAL) 学习不同关键点之间的自适应权重因子，平衡不同部位损失的贡献 \cite{Geng2022KeypointAdaptiveLoss}。结合前景加权（Foreground-Weight）的FoWKAL进一步提升了密集关键点的定位精度 \cite{Geng2022KeypointAdaptiveLoss}。
积分回归改进: 为解决积分回归（soft-argmax）的固有偏差问题，Bias Compensated Integral Regression (BCIR) 通过在解码过程中加入一个简单的偏移项进行补偿 \cite{Huang2021BiasCompensated}。同时，引入高斯先验损失可以加速训练并提高精度 \cite{Huang2021BiasCompensated}。
结构感知损失: 为了使预测的姿态更符合人体解剖学约束，一些损失函数被设计用来鼓励结构合理性。例如，SEAL-Pose将结构化能量作为损失（Structured Energy As Loss），使模型在训练中隐式学习关节间的依赖关系，生成更真实的3D姿态 \cite{Bertoni2022SEALPose}。几何损失函数也常被用于施加骨骼长度、关节角度等约束 \cite{Martinez2017Simple3D}。
面向特定任务/框架的损失: 例如，在基于YOLOv8的姿态估计框架中，研究者提出了新的损失函数如DCIOU，据称相比其他损失函数能降低3-5的损失值 \cite{YourDCIOUPaperKey202X}。 % <-- 修改这里
这些先进损失函数的研发表明，精心设计与任务特性和表示方法相匹配的学习目标，对于提升HPE模型的性能至关重要。

\subsection{数据增强技术 (Data Augmentation Techniques)}
数据增强是提高模型鲁棒性和泛化能力、缓解过拟合（尤其是在训练数据有限或存在偏差时）的关键手段 \cite{Zhou2016HumanPoseSurvey}。除了常见的几何变换（随机缩放、旋转、翻转、裁剪 \cite{Xiao2018SimpleBaselines}），HPE领域还发展出一些特定技术：
遮挡模拟: 模拟现实世界中常见的遮挡情况，是提升模型鲁棒性的重要方法。包括：
\begin{itemize}
    \item 区域级扰动：如Random Erasing \cite{DeVries2017Cutout}、CutOut \cite{DeVries2017Cutout}、随机灰度块替换 \cite{DeVries2017Cutout} 等，随机遮挡图像的一部分区域。
    \item 人体级遮挡生成：专门针对人体实例进行遮挡 \cite{DeVries2017Cutout}。
    \item 合成遮挡数据：利用图形学或GAN生成带有遮挡的训练样本 \cite{Zhang2018PoseResNet}。一些数据集如OCHuman \cite{Zhang2019OCHuman} 和CrowdPose \cite{Li2019CrowdPose} 也专注于提供包含严重遮挡的样本。
\end{itemize}
姿态相关增强:
\begin{itemize}
    \item PoseAug \cite{Gong2021PoseAug}: 专门为视频3D HPE设计的数据增强方法。 % UserConfirmContext60 replaced with Gong2021PoseAug
    \item Pose-Mixup \cite{Cheng2020PoseMix}: 通过混合不同姿态样本生成新的训练数据。
\end{itemize}
基于生成模型的方法: 使用GAN等生成模型来合成更多样化、更逼真的训练数据，例如生成不同光照、服装或姿态的样本 \cite{Zhang2018PoseResNet}。 % User to confirm if Zhang2018PoseResNet is appropriate for GAN-based augmentation, or provide a more specific GAN paper.
半监督学习中的增强: 在半监督学习（SSL）框架中，数据增强扮演着核心角色。一致性正则化方法（consistency-based）通常依赖于对同一无标签样本应用不同强度或类型的增强（如配对的简单-困难增强），并要求模型输出保持一致 \cite{Rasmus2015LadderNetworks}。

\subsection{注意力机制与多尺度融合 (Attention Mechanisms and Multi-scale Fusion)}
有效捕捉上下文信息（局部细节和全局结构）并融合不同尺度的特征对于精确姿态估计至关重要。
注意力机制:
\begin{itemize}
    \item 自注意力 (Self-Attention): Transformer架构的核心，如ViTPose \cite{Xu2022ViTPose} 和PCT \cite{Geng2023PCT} 中使用，能够捕捉图像或序列中任意两个位置之间的长距离依赖关系，有效建模全局上下文和关节点间关系。
    \item 坐标注意力 (Coordinate Attention, CA): 如在CA-HRNet \cite{Hou2021CoordinateAttention} 中应用，通过编码通道关系和长距离空间依赖，同时保留精确的位置信息，有助于提升关键点定位精度。
    \item 卷积块注意力模块 (CBAM): 结合通道注意力和空间注意力，用于轻量级网络（如LAP \cite{Zhang2020LAPNet}, EL-HRNet \cite{Wang2022ELHRNet}）中，以较小代价增强特征表示。
    \item 部件感知注意力 (Part Aware Attention): 如3D-HPE-PAA \cite{Li2022PartAwareAttention} 中使用，使网络能够独立关注不同身体部位，并根据其相关性整合信息，有助于处理遮挡和复杂姿态。 % UserConfirm3DHPEPAA or select from Qin2021TransformerReviewHPE, Zheng2021PoseFormer
\end{itemize}
多尺度特征融合:
\begin{itemize}
    \item Hourglass / CPN / HRNet: 这些经典架构都内建了强大的多尺度处理和融合机制。Hourglass通过反复的下采样-上采样进行融合 \cite{Newell2016StackedHourglass}。CPN利用FPN结构融合多层级特征 \cite{Chen2018CPN}。HRNet通过并行多分辨率子网和跨子网的重复信息交换实现持续、丰富的多尺度融合 \cite{Sun2019HRNet}。
    \item 自适应空间特征融合 (ASFF): 用于解决不同分辨率特征融合时可能存在的冲突问题，如在MS-HRNet \cite{Wang2021HRNetTPAMI} 中应用。
    \item 轻量化融合: 在轻量级网络中，也设计了专门的多尺度融合模块，如Greit-HRNet \cite{Li2021GreitHRNet} 中的融合策略。
\end{itemize}

\subsection{轻量化架构设计 (Lightweight Architecture Design)}
为了满足实时应用和在移动端、嵌入式设备等资源受限平台上的部署需求，研究者们致力于设计轻量且高效的HPE网络 \cite{Liu2020SMSNet}。
核心技术:
\begin{itemize}
    \item 高效卷积: 采用深度可分离卷积（Depthwise Separable Convolution）替代标准卷积，大幅减少参数量和计算量 \cite{Wang2021HRNetTPAMI}。
    \item 模块替换/改进: 使用更高效的模块，如Ghost模块 \cite{Han2020GhostNet}、ShuffleNet中的通道混洗和分组卷积思想（如SMS-Net中的Shuffle-gated block \cite{Liu2020SMSNet}）。
    \item 通道加权/选择: 如Lite-HRNet \cite{Sun2019HRNet} 使用条件通道加权（Conditional Channel Weighting）替代昂贵的逐点卷积。
    \item 动态网络: 如Dite-HRNet \cite{Sun2019HRNet} 采用动态卷积核或动态网络结构。
    \item 稀疏表示: 如SHaRPose \cite{Sun2023SHaRPose} 提出仅在与关键点相关的区域使用稀疏的高分辨率表示。
\end{itemize}
代表模型: Lite-HRNet \cite{Sun2019HRNet}, EfficientHRNet \cite{Wang2020EfficientHRNet}, LAP \cite{Zhang2020LAPNet}, SMS-Net \cite{Liu2020SMSNet}, SHaRPose \cite{Sun2023SHaRPose}, EL-HRNet \cite{Wang2022ELHRNet} 等。这些模型旨在大幅降低模型复杂度（Params和GFLOPs），同时力求保持与大型模型相当的精度。

\subsection{自监督与无监督学习 (Self-supervised and Unsupervised Learning)}
获取大规模、高质量的标注数据（尤其是3D姿态数据）成本高昂 \cite{Zhang2018PoseResNet}。自监督学习（Self-Supervised Learning, SSL）和无监督学习旨在减少对标注数据的依赖 \cite{Zhang2018PoseResNet}。
主要思路:
\begin{itemize}
    \item 几何约束: 利用多视角一致性 \cite{Kocabas2019EpipolarPose}、对极几何约束（用2D信息构建伪3D标签）\cite{Zhang2018PoseResNet}、几何自洽性（如将预测的3D姿态重投影回2D，与输入2D姿态比较）\cite{Chen2019Unsupervised3D} 等作为监督信号。 % UserConfirmContext60 for multi-view consistency, consider Kocabas2019EpipolarPose or Gong2022PoseTriplet
    \item 视频利用: 利用视频中的时间连贯性、光流信息等作为自监督信号 \cite{Gong2022PoseTriplet}。 % UserConfirmContext60 for video utilization, consider Kocabas2019EpipolarPose or Gong2022PoseTriplet
    \item 预训练: 使用如Masked Autoencoders (MAE) \cite{He2022MAE} 等自监督预训练方法为HPE模型提供良好的初始化权重。ViTPose就采用了MAE预训练 \cite{He2022MAE}。
    \item 对抗学习: 结合对抗性训练，例如训练判别器来区分真实的2D姿态和由3D姿态投影生成的"合成"2D姿态，以提升生成3D姿态的真实性 \cite{Chen2019Unsupervised3D}。
\end{itemize}
代表工作: EpipolarPose \cite{Kocabas2019EpipolarPose}, PoseTriplet \cite{Gong2022PoseTriplet}, Chen et al. (Geometric Self-Supervision) \cite{Chen2019Unsupervised3D}, Kundu et al. (Kinematic Structure Preservation) \cite{Kundu2020Kinematic}, PoseResNet (Epipolar Geometry + CBAM + WASP) \cite{Zhang2018PoseResNet}。 % UserConfirmContext60 for Kundu, replaced others based on report
这些技术创新共同推动了HPE领域的发展。可以看到，许多突破源于对表示（如何更有效地表示姿态、图像特征、多尺度信息、结构依赖）和学习目标（如何定义更有效的损失函数、如何利用无标签数据）的深入探索。架构设计（如HRNet, Transformer）、损失函数创新（如Adaptive Wing Loss, SEAL）、数据增强策略以及自监督学习范式，都是围绕这两个核心问题展开的相互关联的解决方案。

\section{当前挑战与未来方向 (Current Challenges and Future Directions)}
尽管基于深度学习的人体姿态估计取得了巨大成功，但仍面临诸多挑战，同时也孕育着新的研究机遇 \cite{Wang2023TransformerSurvey}。

\subsection{尚存的技术挑战 (Remaining Technical Challenges)}
鲁棒性问题:
\begin{itemize}
    \item 遮挡 (Occlusion): 身体部位被物体、其他人或自身遮挡是影响精度的主要因素之一 \cite{Rather2024HPEReview3D}。虽然已有方法通过上下文推理、GAN生成遮挡数据、或设计对遮挡鲁棒的架构（如Transformer）来应对 \cite{Li2019CrowdPose}，但在严重遮挡下仍具挑战性。
    \item 拥挤场景 (Crowded Scenes): 在人群密集的场景中，个体间的相互遮挡、肢体交错使得准确检测和关联关节点变得极为困难 \cite{Li2019CrowdPose}。Top-Down方法依赖准确的人体检测，而Bottom-Up方法则在关节点分组时面临挑战。
    \item 外观与姿态多样性: 人体外观（衣着、体型）、光照变化以及罕见或极端姿态都会给模型的泛化能力带来考验 \cite{Lin2014COCO}。
\end{itemize}
效率与实时性: 高精度模型通常伴随着高计算复杂度（GFLOPs）和模型大小（参数量），难以满足实时应用（如自动驾驶、人机交互）或在资源受限设备（如移动端、边缘设备）上的部署需求 \cite{Rather2024HPEReview3D}。在精度和效率之间取得更好的平衡仍是重要研究方向 \cite{Sun2023SHaRPose}。
数据依赖与泛化: 当前高性能模型严重依赖大规模标注数据集 \cite{Zhou2016HumanPoseSurvey}。标注成本高昂，且现有数据集难以覆盖所有真实世界的场景和人群多样性，导致模型在域外（out-of-domain）或数据稀疏场景下的泛化能力有限 \cite{Rather2024HPEReview3D}。
3D姿态估计的固有难题: 从单目2D图像恢复3D姿态本质上是一个病态问题（ill-posed problem），存在深度模糊性（depth ambiguity）——即多种3D姿态可能投影为同一2D姿态 \cite{Martinez2017Simple3D}。虽然可以利用时间信息、多视角信息或先验知识来缓解，但精确恢复仍然困难。
细粒度姿态与动作捕捉: 对于精细动作（如手势）或微小姿态变化的准确捕捉仍有提升空间 \cite{Geng2022KeypointAdaptiveLoss}。

\subsection{伦理考量：数据集偏见与公平性 (Ethical Considerations: Dataset Bias and Fairness)}
随着HPE技术在监控、医疗、招聘等敏感领域的应用，其伦理影响日益受到关注。
数据集偏见: 主流HPE数据集（如COCO, MPII）在人群分布上存在显著偏见 \cite{Dabra2021BiasHPE}。例如，COCO数据集中男性、浅肤色人群比例偏高，而女性、深肤色、老年人群代表性不足 \cite{Dabra2021BiasHPE}。这种偏见源于数据收集过程，可能反映了现实世界的不平等或采样偏差 \cite{Buolamwini2018GenderShades}。
模型性能差异与公平性: 在有偏见的数据集上训练的模型，很可能对代表性不足的群体表现出较差的性能 \cite{Dabra2021BiasHPE}。例如，评估显示某些模型对男性或浅肤色人群的姿态估计精度更高 \cite{Dabra2021BiasHPE}。这种性能差异可能导致不公平的后果，加剧社会偏见 \cite{Buolamwini2018GenderShades}。
隐私与同意: HPE技术（尤其是结合面部识别时）可能引发隐私担忧，尤其是在公共场所或未经明确同意的情况下使用 \cite{Hartzog2011DataBrokers}。数据收集和使用必须遵守相关法律法规（如GDPR, CCPA）并尊重个人隐私 \cite{Hartzog2011DataBrokers}。
应对策略: 需要构建更多样化、更具代表性的数据集；为现有数据集补充人口统计学标签（如COCO-KD \cite{Dabra2021BiasHPE}）以进行公平性评估；研发偏见检测和缓解算法；在模型开发和部署中遵循伦理准则，确保透明度和问责制 \cite{Dabra2021BiasHPE}。

\subsection{未来研究趋势与方向 (Future Research Trends and Directions)}
结合当前挑战和技术进展，未来HPE研究可能聚焦于以下方向：
提升鲁棒性与泛化能力: 继续研究更有效的遮挡处理机制、人群场景下的解耦方法、以及对光照/外观/姿态变化的适应性 \cite{Wang2023TransformerSurvey}。利用域适应（Domain Adaptation）\cite{Park2024DomainAdaptationHPE} 和域泛化（Domain Generalization）技术提升模型在未见场景下的表现。 % UserConfirmContext60 (Domain Adaption) replaced with Park2024DomainAdaptationHPE
追求极致效率: 持续探索新的轻量化网络架构、模型压缩（剪枝、量化）、硬件加速技术，以实现高精度实时HPE \cite{Sun2023SHaRPose}。研究精度-效率帕累托前沿的优化方法。
减少数据依赖: 大力发展自监督、无监督、弱监督学习方法，充分利用无标签数据 \cite{Zhang2018PoseResNet}。研究少样本学习（Few-shot Learning）和零样本学习（Zero-shot Learning）在HPE中的应用。
深化3D姿态与形状估计: 探索更有效的单目3D重建方法以解决深度模糊 \cite{Martinez2017Simple3D}；结合时间信息的视频3D HPE \cite{Gong2022PoseTriplet}；利用多视角信息融合 \cite{Kocabas2019EpipolarPose}；发展更精细的人体网格恢复（Human Mesh Recovery）技术 \cite{Kanazawa2018HMR}；引入物理约束和生物力学模型提升姿态合理性 \cite{Martinez2017Simple3D}。 % UserConfirmContext60 (Video 3D HPE) & (Multi-view fusion) replaced with more specific suggestions from report
多模态融合: 结合RGB图像与其他模态信息（如深度图、红外、雷达信号 \cite{Toshev2014DeepPose}, IMU传感器数据 \cite{vonMarcard2017IMUFusion}）进行融合，以期在恶劣环境（如低光、遮挡）下获得更鲁棒的估计结果 \cite{Wang2023TransformerSurvey}。
通用人体中心模型: 发展像Hulk \cite{Wang2023Hulk} 这样的通用模型，统一处理多种人体相关任务（检测、分割、姿态、动作、属性识别等），促进知识共享和迁移，提升综合感知能力 \cite{Wang2023Hulk}。
面向特定领域的HPE: 针对体育运动分析 \cite{Thomas2017KeepItSMPL}、医疗健康 \cite{Rather2024HPEReview3D}、人机交互 \cite{Cao2019OpenPose}、动物行为研究（Animal Pose Estimation, APE）\cite{Mathis2018DeepLabCut}、手部姿态估计 \cite{Simon2017HandKeypoint} 等具体应用场景，开发定制化的算法和系统。
公平性与可解释性: 将公平性 \cite{Buolamwini2018GenderShades} 作为模型设计和评估的重要考量，开发可解释的 \cite{Yang2020TransPose} HPE模型，理解其决策过程，确保技术的负责任应用。
HPE领域的研究正从单纯追求基准测试精度，向更广阔的维度拓展。解决现实世界中的鲁棒性、效率、数据和伦理挑战，并赋能下游应用，将是未来研究的核心驱动力。

\section{结论 (Conclusion)}
基于深度学习的人体姿态估计在过去二十年中取得了革命性的进步。从DeepPose开创性的坐标回归，到热力图方法的成熟与流行（以CPM、Stacked Hourglass、CPN、SimpleBaseline为代表），再到HRNet对高分辨率表示的极致追求，直至当前Transformer架构（如ViTPose、PCT、Hulk）引领的捕捉全局依赖的新浪潮，技术演进的脉络清晰可见。这一过程伴随着核心方法论的不断迭代（自顶向下 vs. 自底向上，热力图 vs. 回归）以及关键技术（如损失函数、数据增强、注意力机制、轻量化设计、自监督学习）的持续创新。当前，SOTA性能呈现出基准依赖性和动态变化的特点。ViTPose在COCO数据集上表现优异，PCT在MPII上领先，Hulk则在AIC和3D任务（如3DPW）上展现出强大的通用能力。这表明不同架构在应对特定挑战（如COCO的复杂场景 vs. MPII的多样姿态）时各有侧重。同时，模型性能与其复杂度（参数量、计算量）通常正相关，但轻量化研究正努力打破这一限制，以满足实际应用需求。尽管成就斐然，HPE领域仍面临严峻挑战：在遮挡、拥挤等复杂真实场景下的鲁棒性有待提高；高精度模型部署于资源受限平台的效率瓶颈亟待突破；对大规模标注数据的依赖限制了技术的广泛应用和泛化能力；3D姿态估计的深度模糊问题仍需更优解决方案；数据集偏见带来的公平性问题日益凸显，对技术的负责任应用提出了更高要求。未来的研究将围绕这些挑战展开，重点方向包括：提升模型在真实复杂环境下的鲁棒性和泛化能力；研发更高效的轻量化模型；探索自监督、无监督等低数据依赖的学习范式；深化3D姿态与人体网格恢复技术；融合多模态信息；构建通用人体中心感知模型；面向特定应用领域进行深度优化；并高度重视和解决公平性与伦理问题。人体姿态估计技术正从实验室走向更广泛的应用，其未来的发展将更加注重实用性、鲁棒性、效率和责任感。

\section*{致谢 (Acknowledgements)} % Unnumbered section
致谢内容 (可选)...

% Bibliography
% Create a refs.bib file for your references
\printbibliography % Add this for biblatex at the end of the document

\end{document}

% ===============================================
% Example refs.bib content (save as refs.bib in the same directory)
% ===============================================
% @article{example_article,
%   author  = {Author, A. N.},
%   title   = {Title of the Article},
%   journal = {Journal Name},
%   year    = {2023},
%   volume  = {1},
%   number  = {2},
%   pages   = {100-110}
% }
%
% @inproceedings{example_conference,
%   author    = {Author, B. C. and Author, D. E.},
%   title     = {Title of the Conference Paper},
%   booktitle = {Proceedings of the Conference},
%   year      = {2023},
%   pages     = {200-210}
% }
% ===============================================
